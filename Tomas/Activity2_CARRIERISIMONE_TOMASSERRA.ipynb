{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f96742",
   "metadata": {},
   "source": [
    "## EXERCISE 0\n",
    "\n",
    "Download and extract the Python version of the CIFAR dataset from the CIFAR website.  \n",
    "The dataset is structured as follows:\n",
    "\n",
    "- **5 training batches** of 10,000 images each (50,000 images total)  \n",
    "- **1 test batch** of 10,000 images  \n",
    "\n",
    "Each batch file contains a **dictionary** with the following elements:\n",
    "\n",
    "- **`data`** – a 10,000 × 3,072 NumPy array of `uint8`.  \n",
    "  Each row represents a 32×32 color image:  \n",
    "  - The first 1,024 entries are the red channel,  \n",
    "  - The next 1,024 entries are the green channel,  \n",
    "  - The final 1,024 entries are the blue channel.  \n",
    "  Images are stored in **row-major order**, i.e., the first 32 entries correspond to the red values of the first row of the image.\n",
    "\n",
    "- **`labels`** – a list of 10,000 integers in the range 0–9.  \n",
    "  The number at index `i` indicates the label of the `i`th image in `data`.\n",
    "\n",
    "The dataset also contains another file called **`batches.meta`**, which is a Python dictionary with the following entry:\n",
    "\n",
    "- **`label_names`** – a 10-element list giving meaningful names to the numeric labels in the `labels` array described above.  \n",
    "  For example:  \n",
    "  ```python\n",
    "  label_names[0] == \"airplane\"\n",
    "  label_names[1] == \"automobile\"\n",
    "  # etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f3b62",
   "metadata": {},
   "source": [
    "## EXERCISE 1\n",
    "Create a Dataset class to read the data. When initialized, this class should\n",
    "take as arguments the path to the data, the transformation to be applied to each\n",
    "image and if the dataset is train or test. If train you should load all\n",
    "the 5 batches that composed the whole CIFAR training set. [2.0 pts]\n",
    "\n",
    "The resulting class, `CIFAR10Dataset`, was designed to integrate seamlessly with the PyTorch framework, allowing full use of PyTorch tools for subsequent data processing and augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3675b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import (roc_auc_score, roc_curve, auc,\n",
    "                             confusion_matrix, classification_report, accuracy_score)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    CIFAR-10 dataset class compatible with PyTorch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to the CIFAR-10 batch files.\n",
    "    data_type : str, default='train'\n",
    "        Type of dataset to load. Must be 'train' or 'test'.\n",
    "    transform : callable, optional\n",
    "        A function/transform to apply to each image.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __len__()\n",
    "        Returns the number of samples in the dataset.\n",
    "    __getitem__(idx)\n",
    "        Returns the image and label at the given index, applying the transform if specified.\n",
    "    visualize(img, mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "        Display a single image (tensor or NumPy array), un-normalizing if needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, data_type='train', transform=None):\n",
    "\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load training data\n",
    "        if data_type == 'train':\n",
    "            data_list = []\n",
    "            labels_list = []\n",
    "            #Iterate for each of the 5 training batches\n",
    "            for i_batch in range(1, 6):\n",
    "                file = os.path.join(path, f\"data_batch_{i_batch}\")\n",
    "                with open(file, 'rb') as fo:\n",
    "                    # Deserialize binary batch files\n",
    "                    batch = pickle.load(fo, encoding='bytes')\n",
    "                    # Reshape data to (num_images, channels, height, width)\n",
    "                    imgs = np.reshape(batch[b'data'], (10000, 3, 32, 32))\n",
    "                    data_list.append(imgs)\n",
    "                    #Creates one single label list for training\n",
    "                    labels_list.extend(batch[b'labels'])\n",
    "            self.data = np.vstack(data_list)  # combines all batches of train in a 4D Numpy array (50000,3,32,32)\n",
    "            self.labels = np.array(labels_list) # converts all labels of train in a 1D Numpy array (50000,)\n",
    "\n",
    "        # Load test data\n",
    "        elif data_type == 'test':\n",
    "            file = os.path.join(path, \"test_batch\")\n",
    "            with open(file, 'rb') as fo:\n",
    "                # Deserialize binary batch file\n",
    "                batch = pickle.load(fo, encoding='bytes')\n",
    "                # Reshape images to (num_images, channels, height, width)\n",
    "                self.data = np.reshape(batch[b'data'], (10000, 3, 32, 32))\n",
    "                self.labels = np.array(batch[b'labels']) # converts all labels of test in a 1D Numpy array (50000,)\n",
    "        else:\n",
    "            raise ValueError(\"data_type must be 'train' or 'test'\")\n",
    "\n",
    "    # Return number of samples\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    #Function overrides __getitem__ standard python method called when an object is indexed.\n",
    "    #The function will now return one sample (image and label) by index when object is indexed.\n",
    "    # Any specified transformation is applied on-the-fly for efficiency and to allow online augmentation.\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data[idx]       # single image in CHW format (3,32,32)\n",
    "        label = self.labels[idx]   # corresponding label\n",
    "        img = np.transpose(img, (1, 2, 0))  # convert to HWC format for transforms/visualization\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)    # apply optional transform;\n",
    "        return img, label\n",
    "\n",
    "    # Display a single image (tensor or NumPy array)\n",
    "    def visualize(self, img, mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)):\n",
    "        #Assuming data is transformed\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            # Check if the image is already normalized otherwise un-normalize\n",
    "            if img.min() < 0 or img.max() > 1:\n",
    "                mean_t = torch.tensor(mean).view(3,1,1)\n",
    "                std_t  = torch.tensor(std).view(3,1,1)\n",
    "                img = img * std_t + mean_t  # Un-normalize\n",
    "            npimg = img.numpy()\n",
    "            plt.imshow(npimg)     \n",
    "        else:\n",
    "            plt.imshow(img)          # For NumPy arrays\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e2cfc8",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Build a CNN model to predict a class from the input image (you can use\n",
    "the Conv2D module and one of the plenty pooling layers already implemented).\n",
    "Which are the main hyperparameters you should set to build the main model?\n",
    "Good practice is to build the model class as general as possible, and specify the\n",
    "hyperparaemeters when the class is called. [2.0 pts]\n",
    "\n",
    "The resulting class, `GeneralCNN`, was designed to integrate seamlessly with the PyTorch framework, allowing full use of PyTorch tools. Specifically, the class inherits from `nn.Module`, which enables automatic parameter management, supports custom forward passes, allows gradient computation via autograd, and ensures compatibility with optimizers and model saving/loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2d91b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODULES in PyTorch are the fundamental building blocks of neural networks.\n",
    "A module is any class that inherits from `nn.Module` and can encapsulate both\n",
    "layers with learnable parameters (like `nn.Linear` or `nn.Conv2d` or personalized Moudles like GeneralCNN) \n",
    "and other submodules, forming a hierarchical structure.\n",
    "Each module defines a `forward` method specifying how input data is transformed\n",
    "into output, and all parameters registered within the module are automatically\n",
    "tracked for gradient computation, optimization, and serialization.\n",
    "\"\"\"\n",
    "\n",
    "class GeneralCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    General CNN class compatible with PyTorch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int, default=3\n",
    "        Number of input channels (e.g., 3 for RGB images).\n",
    "    num_classes : int, default=10\n",
    "        Number of output classes for classification.\n",
    "    conv_layers : list of tuples, default=[(6,5), (16,5)]\n",
    "        Each tuple defines a convolutional layer as (out_channels, kernel_size).\n",
    "    pool_type : str, default='max'\n",
    "        Type of pooling layer, either 'max' or 'avg'.\n",
    "    pool_kernel : int, default=3\n",
    "        Kernel size of the pooling layer.\n",
    "    pool_stride : int, default=2\n",
    "        Stride of the pooling layer.\n",
    "    fc_layers : list of int, default=[120, 84]  \n",
    "        Specifies the number of neurons in each fully connected layer \n",
    "        before the output layer and after the flattening.\n",
    "    activation : str, default='relu'\n",
    "        Activation function: 'relu', 'leaky_relu', or 'elu'.\n",
    "    input_size : tuple, default=(32,32)\n",
    "        Input image size as (height, width).\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    forward(x)\n",
    "        Computes the forward pass of the network.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels=3,\n",
    "                 num_classes=10,\n",
    "                 conv_layers=[(6, 5), (16, 5)],\n",
    "                 pool_type='max',\n",
    "                 pool_kernel=3,\n",
    "                 pool_stride=2,\n",
    "                 fc_layers=[120, 84],\n",
    "                 activation='relu',\n",
    "                 input_size=(32, 32)):\n",
    "        \n",
    "        #Call the init method of the nn.Module class\n",
    "        super(GeneralCNN, self).__init__()\n",
    "\n",
    "        # Select activation function\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 'leaky_relu':\n",
    "            self.activation = nn.LeakyReLU()\n",
    "        elif activation == 'elu':\n",
    "            self.activation = nn.ELU()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation\")\n",
    "\n",
    "        # Build convolutional layers\n",
    "        self.layers = nn.ModuleList() #Create an object list of modules for the layers\n",
    "        current_channels = in_channels\n",
    "        for out_channels, kernel_size in conv_layers:\n",
    "            conv = nn.Conv2d(current_channels, out_channels, kernel_size=kernel_size)\n",
    "            self.layers.append(conv) #use the append of the nn.Modulelist class, to append the module\n",
    "            current_channels = out_channels\n",
    "\n",
    "        # Define pooling layer\n",
    "        if pool_type == 'max':\n",
    "            self.pool = nn.MaxPool2d(kernel_size=pool_kernel, stride=pool_stride)\n",
    "        elif pool_type == 'avg':\n",
    "            self.pool = nn.AvgPool2d(kernel_size=pool_kernel, stride=pool_stride)\n",
    "        else:\n",
    "            raise ValueError(\"pool_type must be 'max' or 'avg'\")\n",
    "\n",
    "        self.fc_config = fc_layers\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Compute flattened size after conv + pool layers using a dummy input\n",
    "        # Specifically, `torch.no_grad()` is used to avoid tracking gradients since no\n",
    "        # backward pass or parameter update is needed during this computation.\n",
    "        with torch.no_grad():\n",
    "            # Creates a zero tensor of size [1, C, H, W] (1 image, C channels, H height, W width)\n",
    "            # This dummy input is used to compute the flattened size after conv + pool layers;\n",
    "            # the first value represents the batch size and can be any number selected\n",
    "            dummy = torch.zeros(1, in_channels, input_size[0], input_size[1])\n",
    "            x = dummy\n",
    "            for conv in self.layers:\n",
    "                x = conv(x)\n",
    "                x = self.activation(x)\n",
    "                if self.pool is not None:\n",
    "                    x = self.pool(x)\n",
    "            # This will flatten all dimensions except the batch and return the total number of features per image\n",
    "            flattened_size = torch.flatten(x, start_dim=1).shape[1]\n",
    "\n",
    "        # Build fully connected layers\n",
    "        self.fc_layers = nn.ModuleList() #Create an object list of modules for the fully connected\n",
    "        input_size_fc = flattened_size\n",
    "        for units in self.fc_config:\n",
    "            self.fc_layers.append(nn.Linear(input_size_fc, units))\n",
    "            input_size_fc = units\n",
    "        self.fc_layers.append(nn.Linear(input_size_fc, self.num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input tensor of shape (batch_size, in_channels, height, width).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Output logits of shape (batch_size, num_classes). \n",
    "            Logits are the raw, unnormalized scores produced by the network for each class.\n",
    "            They are not probabilities yet. To convert logits to probabilities, the torch.softmax() \n",
    "            function can be used.\n",
    "        \"\"\"\n",
    "        for conv in self.layers:\n",
    "            x = conv(x)\n",
    "            x = self.activation(x)\n",
    "            if self.pool is not None:\n",
    "                x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten for fully connected layers\n",
    "        for i, fc in enumerate(self.fc_layers):\n",
    "            if i < len(self.fc_layers) - 1:\n",
    "                x = self.activation(fc(x))\n",
    "            else:\n",
    "                x = fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6922bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    # --- ADDED METRICS ---\n",
    "\n",
    "What changed / added:\n",
    " - A helper function `metrics_from_confusion_matrix(cm, class_names=None)` that\n",
    "   computes TP, FP, FN, TN and derived metrics (precision, recall/sensitivity,\n",
    "   specificity, F1, support) per class and macro averages.\n",
    "   (Marked \"# --- ADDED METRICS ---\" where defined and where used.)\n",
    " - The run_experiment() routine now calls this helper for both train and test\n",
    "   confusion matrices, prints the per-class metrics and saves them as CSV.\n",
    "   (Marked \"# --- ADDED METRICS ---\" where results are printed/saved.)\n",
    " - The script preserves previous behavior: timing, plotting and saving confusions,\n",
    "   train-vs-test confusion difference, and two experiments (normalized vs plain).\n",
    "\n",
    "Run: python train_cifar_confusion_metrics.py\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# --- ADDED METRICS ---\n",
    "# Helper: compute per-class metrics from confusion matrix (one-vs-all)\n",
    "# This follows the approach this requested article:\n",
    "# https://towardsdatascience.com/multi-class-classification-extracting-performance-metrics-from-the-confusion-matrix-b379b427a872/\n",
    "# ----------------------------\n",
    "def metrics_from_confusion_matrix(cm, class_names=None):\n",
    "    \"\"\"\n",
    "    Given a square confusion matrix cm (actual rows, predicted cols),\n",
    "    compute per-class TP, FP, FN, TN and derived metrics:\n",
    "      precision, recall (sensitivity), specificity, f1, support\n",
    "\n",
    "    Returns:\n",
    "      metrics_per_class: dict[class_name or index] -> dict of metrics\n",
    "      summary: dict with macro-averages and overall accuracy\n",
    "    \"\"\"\n",
    "    cm = np.array(cm, dtype=np.int64)\n",
    "    n_classes = cm.shape[0]\n",
    "    total = cm.sum()\n",
    "    diag = np.diag(cm)\n",
    "    metrics_per_class = {}\n",
    "    eps = 1e-12\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        TP = int(cm[i, i])\n",
    "        FP = int(cm[:, i].sum() - TP)\n",
    "        FN = int(cm[i, :].sum() - TP)\n",
    "        TN = int(total - TP - FP - FN)\n",
    "\n",
    "        precision = TP / (TP + FP + eps)\n",
    "        recall = TP / (TP + FN + eps)  # sensitivity\n",
    "        specificity = TN / (TN + FP + eps)\n",
    "        f1 = 2 * precision * recall / (precision + recall + eps)\n",
    "        support = int(cm[i, :].sum())\n",
    "\n",
    "        name = class_names[i] if class_names is not None else str(i)\n",
    "        metrics_per_class[name] = {\n",
    "            'TP': TP, 'FP': FP, 'FN': FN, 'TN': TN,\n",
    "            'precision': precision, 'recall': recall,\n",
    "            'specificity': specificity, 'f1': f1, 'support': support\n",
    "        }\n",
    "\n",
    "    # Overall metrics\n",
    "    accuracy = diag.sum() / (total + eps)\n",
    "    # macro averages\n",
    "    macro_precision = np.mean([m['precision'] for m in metrics_per_class.values()])\n",
    "    macro_recall = np.mean([m['recall'] for m in metrics_per_class.values()])\n",
    "    macro_f1 = np.mean([m['f1'] for m in metrics_per_class.values()])\n",
    "\n",
    "    summary = {\n",
    "        'accuracy': accuracy,\n",
    "        'macro_precision': macro_precision,\n",
    "        'macro_recall': macro_recall,\n",
    "        'macro_f1': macro_f1,\n",
    "        'total': int(total)\n",
    "    }\n",
    "\n",
    "    return metrics_per_class, summary\n",
    "# ----------------------------\n",
    "# --- END ADDED METRICS ---\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d20409c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This class is reponsable for performing to expose the method for \n",
    "performing the training of the model, to evaluate it and to save the metrics\n",
    "'''\n",
    "\n",
    "\n",
    "class Experiment:\n",
    "    def __init__(self, exp_name, transform, data_path='data', batch_size=128, num_epochs=50,\n",
    "                 device=None, num_workers=0, pin_memory=False, class_names=None):\n",
    "        self.exp_name = exp_name\n",
    "        self.transform = transform\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "        self.class_names = class_names\n",
    "\n",
    "\n",
    "        # Instanciate datasets & loaders\n",
    "        self.train_dataset = CIFAR10Dataset(path=data_path, data_type='train', transform=transform)\n",
    "        self.test_dataset  = CIFAR10Dataset(path=data_path, data_type='test', transform=transform)\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                       num_workers=num_workers, pin_memory=pin_memory)\n",
    "        self.eval_train_loader = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                   num_workers=num_workers, pin_memory=pin_memory)\n",
    "        self.test_loader = DataLoader(self.test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                      num_workers=num_workers, pin_memory=pin_memory)\n",
    "        \n",
    "        # Visualize first image, to see if data was loaded correctly \n",
    "        try:\n",
    "            img0, label0 = self.train_dataset[0]\n",
    "            print(f\"Sample visualization (exp={exp_name}) - Label: {label0}\")\n",
    "            # If the transform includes Normalize((0.5,...),(0.5,...)) this will unnormalize inside visualize\n",
    "            # We cannot automatically detect the Normalize params reliably here, so we assume the common .5/.5 default.\n",
    "            self.train_dataset.visualize(img0, mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "        except Exception as e:\n",
    "            print(\"Could not visualize sample image:\", e)\n",
    "\n",
    "        # Instanciate model, criterion and optimizer\n",
    "        self.model = GeneralCNN()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
    "        # model.parameters() returns an iterator over all learnable parameters (weights and biases).\n",
    "        # The optimizer updates these parameters by exploiting the iteratior inside the class during training based on the gradients\n",
    "\n",
    "    def train_epoch(self):\n",
    "        \"\"\"Train the model for a single epoch and return the average epoch loss.\"\"\"\n",
    "        self.model.train()                              # Enable training mode (dropout, BN updates)\n",
    "        running_loss = 0.0                              # Accumulate batch losses over the epoch\n",
    "\n",
    "        for images, labels in self.train_loader:        # Iterate over training batches\n",
    "            images = images.to(self.device, non_blocking=(self.num_workers > 0))   # Move images to device\n",
    "            labels = labels.to(self.device, non_blocking=(self.num_workers > 0))   # Move labels to device\n",
    "\n",
    "            self.optimizer.zero_grad()                  # Clear gradients from previous iteration\n",
    "            outputs = self.model(images)                # Forward pass: compute predictions\n",
    "            loss = self.criterion(outputs, labels)      # Compute loss\n",
    "            loss.backward()                             # Backward pass: compute gradients\n",
    "            self.optimizer.step()                       # Update model parameters\n",
    "\n",
    "            running_loss += loss.item()                 # Accumulate loss for this batch\n",
    "\n",
    "        return running_loss / len(self.train_loader)    # Return average epoch loss\n",
    "\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Train the model for all epochs, tracking loss and timing.\"\"\"\n",
    "        print(f\"\\n=== Starting training for experiment: {self.exp_name} ===\")\n",
    "        print()\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        opt_params = sum(p.numel() for g in self.optimizer.param_groups for p in g['params'])\n",
    "        print(f\"Total model params: {total_params}, Optimizer params: {opt_params}\")\n",
    "        assert total_params == opt_params, \"Parameter count mismatch: optimizer may not include all model parameters\"\n",
    "        train_losses = []                               # Store average loss per epoch\n",
    "        epoch_times = []                                # Store duration of each epoch\n",
    "\n",
    "        total_start = time.perf_counter()               # Start total training timer\n",
    "\n",
    "        for epoch in range(self.num_epochs):            # Loop over epochs\n",
    "            epoch_start = time.perf_counter()           # Start timer for this epoch\n",
    "\n",
    "            epoch_loss = self.train_epoch()             # Train for one epoch\n",
    "\n",
    "            epoch_end = time.perf_counter()             # End timer\n",
    "            epoch_duration = epoch_end - epoch_start    # Compute epoch duration\n",
    "\n",
    "            train_losses.append(epoch_loss)             # Save epoch loss\n",
    "            epoch_times.append(epoch_duration)          # Save epoch time\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{self.num_epochs}] - \"\n",
    "                f\"Avg Loss: {epoch_loss:.4f} - Time: {epoch_duration:.2f}s\")\n",
    "\n",
    "        total_end = time.perf_counter()                 # End total training timer\n",
    "        total_training_time = total_end - total_start   # Compute total training time\n",
    "\n",
    "        print(f\"Total training time for {self.exp_name}: {total_training_time:.2f}s\")\n",
    "\n",
    "        # Store metrics for later use (plots, logs, etc.)\n",
    "        self.train_losses = train_losses\n",
    "        self.epoch_times = epoch_times\n",
    "\n",
    "        return train_losses, epoch_times\n",
    "\n",
    "\n",
    "\n",
    "    def eval_train(self):\n",
    "        self.model.eval()  # Set model to evaluation mode (disables dropout, batchnorm updates)\n",
    "        all_probs, all_labels = [], []  # Lists to store batch-wise probabilities and labels\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "            for images, labels in self.eval_train_loader:\n",
    "                images = images.to(self.device)  # Move batch to device (CPU/GPU)\n",
    "                outputs = self.model(images)     # Forward pass, outputs are logits of shape (batch_size, num_classes)\n",
    "                probs = torch.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "                all_probs.append(probs.cpu())    # Move to CPU and collect\n",
    "                all_labels.append(labels.cpu())  # Move to CPU and collect\n",
    "\n",
    "        # Concatenate all batches along the first dimension\n",
    "        self.all_probs_train = torch.cat(all_probs, dim=0).numpy()  # Shape: (N_train, C)\n",
    "        self.all_labels_train = torch.cat(all_labels, dim=0).numpy() # Shape: (N_train,)\n",
    "\n",
    "        # Return full probability and label tensors\n",
    "        return self.all_probs_train, self.all_labels_train\n",
    "        # For example, CIFAR-10: N_train=50000, C=10 -> all_probs_train: (50000, 10), all_labels_train: (50000,)\n",
    "\n",
    "    def eval_test(self):\n",
    "        self.model.eval()  # Set model to evaluation mode\n",
    "        all_probs, all_labels = [], []  # Lists to store batch-wise probabilities and labels\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.test_loader:\n",
    "                images = images.to(self.device)  # Move batch to device\n",
    "                outputs = self.model(images)      # Forward pass, logits (batch_size, num_classes)\n",
    "                probs = torch.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "                all_probs.append(probs.cpu())     # Collect probabilities\n",
    "                all_labels.append(labels.cpu())   # Collect labels\n",
    "\n",
    "        # Concatenate all batches\n",
    "        self.all_probs_test = torch.cat(all_probs, dim=0).numpy()   # Shape: (N_test, C)\n",
    "        self.all_labels_test = torch.cat(all_labels, dim=0).numpy() # Shape: (N_test,)\n",
    "\n",
    "        # Return full probability and label tensors\n",
    "        return self.all_probs_test, self.all_labels_test\n",
    "        # For example, CIFAR-10: N_test=10000, C=10 -> all_probs_test: (10000, 10), all_labels_test: (10000,)\n",
    "\n",
    "\n",
    "\n",
    "    def compute_metrics(self, prob, labels):\n",
    "        #---------------------\n",
    "        # ACCURACY computation\n",
    "        #---------------------\n",
    "        pred = prob.argmax(axis=1)  # Predicted class indices\n",
    "        accuracy = accuracy_score(labels, pred)\n",
    "        report = classification_report(labels, pred, digits=4)\n",
    "\n",
    "        #---------------------\n",
    "        # ROC & AUC computation\n",
    "        #---------------------\n",
    "        n_classes = len(self.class_names) if self.class_names is not None else 10\n",
    "        all_labels_bin = label_binarize(labels, classes=np.arange(n_classes))\n",
    "\n",
    "        roc_curves = {}  # Store FPR, TPR, AUC for each class\n",
    "        try:\n",
    "            for i in range(n_classes):\n",
    "                fpr, tpr, _ = roc_curve(all_labels_bin[:, i], prob[:, i])\n",
    "                auc_value = auc(fpr, tpr)\n",
    "                roc_curves[i] = {'fpr': fpr, 'tpr': tpr, 'auc': auc_value}\n",
    "            roc_auc_overall = roc_auc_score(all_labels_bin, prob, multi_class='ovr')\n",
    "        except Exception:\n",
    "            roc_curves = None\n",
    "            roc_auc_overall = float('nan')\n",
    "\n",
    "        #---------------------\n",
    "        # CONFUSION MATRICES\n",
    "        #---------------------\n",
    "        cm = confusion_matrix(labels, pred)\n",
    "\n",
    "        # --- PER-CLASS METRICS ---\n",
    "        metrics_per_class, metrics_summary = metrics_from_confusion_matrix(cm, self.class_names)\n",
    "\n",
    "        # Return all metrics including ROC curves\n",
    "        return accuracy, report, roc_auc_overall, roc_curves, cm, metrics_per_class, metrics_summary\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab0956df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Sample visualization (exp=normalized) - Label: 6\n",
      "Could not visualize sample image: cannot access local variable 't' where it is not associated with a value\n",
      "Sample visualization (exp=not_normalized) - Label: 6\n",
      "Could not visualize sample image: cannot access local variable 't' where it is not associated with a value\n",
      "\n",
      "=== Running experiment: normalized ===\n",
      "\n",
      "=== Starting training for experiment: normalized ===\n",
      "\n",
      "Total model params: 44726, Optimizer params: 44726\n",
      "Epoch [1/2] - Avg Loss: 2.2986 - Time: 9.08s\n",
      "Epoch [2/2] - Avg Loss: 2.2694 - Time: 8.40s\n",
      "Total training time for normalized: 17.48s\n",
      "Saved loss plot to plots/normalized/loss.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ROC curves to plots/normalized/roc_curves_train.png\n",
      "Saved ROC curves to plots/normalized/roc_curves_test.png\n",
      "Saved confusion matrix to plots/normalized/confusion_train.png\n",
      "Saved confusion matrix to plots/normalized/confusion_test.png\n",
      "Saved confusion matrix to plots/normalized/confusion_diff.png\n",
      "\n",
      "--- Summary for normalized ---\n",
      "Train accuracy: 0.1852, Test accuracy: 0.1860, Test ROC AUC: 0.7046\n",
      "Total training time: 17.48s, Epoch times: [9.08, 8.4]\n",
      "\n",
      "=== Running experiment: not_normalized ===\n",
      "\n",
      "=== Starting training for experiment: not_normalized ===\n",
      "\n",
      "Total model params: 44726, Optimizer params: 44726\n",
      "Epoch [1/2] - Avg Loss: 2.3030 - Time: 10.10s\n",
      "Epoch [2/2] - Avg Loss: 2.2991 - Time: 6.35s\n",
      "Total training time for not_normalized: 16.44s\n",
      "Saved loss plot to plots/not_normalized/loss.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/torch_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ROC curves to plots/not_normalized/roc_curves_train.png\n",
      "Saved ROC curves to plots/not_normalized/roc_curves_test.png\n",
      "Saved confusion matrix to plots/not_normalized/confusion_train.png\n",
      "Saved confusion matrix to plots/not_normalized/confusion_test.png\n",
      "Saved confusion matrix to plots/not_normalized/confusion_diff.png\n",
      "\n",
      "--- Summary for not_normalized ---\n",
      "Train accuracy: 0.1373, Test accuracy: 0.1328, Test ROC AUC: 0.6387\n",
      "Total training time: 16.44s, Epoch times: [10.1, 6.35]\n",
      "\n",
      "Saved comparison summary to plots/comparison_summary.txt\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to plot and save confusion matrix\n",
    "def plot_cm(cm, title, path, class_names=None):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    thresh = cm.max() / 2. if cm.max() > 0 else 0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(int(cm[i, j]), 'd'),\n",
    "                        horizontalalignment=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    if class_names is not None:\n",
    "        plt.xticks(np.arange(len(class_names)), class_names, rotation=45, ha='right')\n",
    "        plt.yticks(np.arange(len(class_names)), class_names)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix to {path}\")\n",
    "\n",
    "\n",
    "# Save per-class metrics as CSVs for easy inspection\n",
    "def save_metrics_csv(metrics_per_class, summary, csv_path):\n",
    "    # metrics_per_class is dict[class] -> dict(metrics)\n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['class', 'TP', 'FP', 'FN', 'TN', 'precision', 'recall', 'specificity', 'f1', 'support']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for cls, metrics in metrics_per_class.items():\n",
    "            row = {'class': cls}\n",
    "            row.update({k: metrics[k] for k in ['TP', 'FP', 'FN', 'TN', 'precision', 'recall', 'specificity', 'f1', 'support']})\n",
    "            writer.writerow(row)\n",
    "        # write summary as final rows\n",
    "        writer.writerow({})\n",
    "        writer.writerow({'class': 'SUMMARY', 'TP': '', 'FP': '', 'FN': '', 'TN': '', 'precision': summary['macro_precision'],\n",
    "                            'recall': summary['macro_recall'], 'specificity': '', 'f1': summary['macro_f1'], 'support': summary['total']})\n",
    "        \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def plot_roc_curves(roc_curves, class_names=None, title=\"ROC Curves\", save_path=None):\n",
    "    \"\"\"\n",
    "    Plot multi-class ROC curves from a dict of {class_idx: {'fpr':..., 'tpr':..., 'auc':...}}.\n",
    "    \"\"\"\n",
    "    if roc_curves is None:\n",
    "        print(\"No ROC curves to plot.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    for class_idx, data in roc_curves.items():\n",
    "        fpr = data['fpr']\n",
    "        tpr = data['tpr']\n",
    "        auc_value = data['auc']\n",
    "        name = class_names[class_idx] if class_names is not None else str(class_idx)\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_value:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved ROC curves to {save_path}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def  plot_loss(exp_name,num_epochs,train_losses, plots_dir):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.title(f'Training Loss over Epochs ({exp_name})')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save inside the experiment's plot directory\n",
    "    loss_path = os.path.join(plots_dir, \"loss.png\")\n",
    "    plt.savefig(loss_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved loss plot to {loss_path}\")\n",
    "\n",
    "\n",
    "\n",
    "#----------------\n",
    "#     MAIN\n",
    "#-----------------\n",
    "if __name__ == \"__main__\":\n",
    "    import torch, os, pickle, csv\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from torchvision import transforms\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "\n",
    "    # ----------------------------\n",
    "    # Seeds and device\n",
    "    # ----------------------------\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Data paths and parameters\n",
    "    # ----------------------------\n",
    "    data_path = \"data\"\n",
    "    num_workers = 0\n",
    "    pin_memory = True if device.type == 'cuda' else False\n",
    "    batch_size = 128\n",
    "    num_epochs = 2\n",
    "\n",
    "    transform_norm = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    transform_plain = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    # ----------------------------\n",
    "    # Load class names\n",
    "    # ----------------------------\n",
    "    # label_names_file = os.path.join(data_path, 'batches.meta')\n",
    "    # with open(label_names_file, 'rb') as fo:\n",
    "    #     labels_name = pickle.load(fo, encoding='bytes')\n",
    "    #     labels_name=list(labels_name.keys())\n",
    "\n",
    "\n",
    "    labels_name = ['airplane', 'automobile', 'bird', 'cat',\n",
    "                   'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "    n_classes = len(labels_name)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Instantiate experiments\n",
    "    # ----------------------------\n",
    "    res_norm = Experiment(\"normalized\", transform_norm,\n",
    "                          data_path=data_path,\n",
    "                          batch_size=batch_size,\n",
    "                          num_epochs=num_epochs,\n",
    "                          device=device,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          class_names=labels_name)\n",
    "\n",
    "    res_plain = Experiment(\"not_normalized\", transform_plain,\n",
    "                           data_path=data_path,\n",
    "                           batch_size=batch_size,\n",
    "                           num_epochs=num_epochs,\n",
    "                           device=device,\n",
    "                           num_workers=num_workers,\n",
    "                           pin_memory=pin_memory,\n",
    "                           class_names=labels_name)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # ----------------------------\n",
    "    # Run experiments\n",
    "    # ----------------------------\n",
    "    for ex in [res_norm, res_plain]:\n",
    "        print(f\"\\n=== Running experiment: {ex.exp_name} ===\")\n",
    "\n",
    "        plots_dir = os.path.join(\"plots\", ex.exp_name)\n",
    "        os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "        # Train and plot loss\n",
    "        ex.train()\n",
    "        plot_loss(ex.exp_name,ex.num_epochs,ex.train_losses, plots_dir)\n",
    "\n",
    "\n",
    "        # Evaluate\n",
    "        prob_train, labels_train = ex.eval_train()\n",
    "        prob_test, labels_test = ex.eval_test()\n",
    "\n",
    "        # Compute metrics\n",
    "        acc_train, report_train, roc_auc_train, roc_curves_train, cm_train, metrics_train_per_class, metrics_train_summary = ex.compute_metrics(prob_train, labels_train)\n",
    "        acc_test, report_test, roc_auc_test, roc_curves_test, cm_test, metrics_test_per_class, metrics_test_summary = ex.compute_metrics(prob_test, labels_test)\n",
    "\n",
    "\n",
    "        # Plot ROC curves for train\n",
    "        plot_roc_curves(\n",
    "            roc_curves_train,\n",
    "            class_names=ex.class_names,\n",
    "            title=f'Multi-class ROC Curves (Train) - {ex.exp_name}',\n",
    "            save_path=os.path.join(plots_dir, \"roc_curves_train.png\")\n",
    "        )\n",
    "\n",
    "        # Plot ROC curves for test\n",
    "        plot_roc_curves(\n",
    "            roc_curves_test,\n",
    "            class_names=ex.class_names,\n",
    "            title=f'Multi-class ROC Curves (Test) - {ex.exp_name}',\n",
    "            save_path=os.path.join(plots_dir, \"roc_curves_test.png\")\n",
    "        )\n",
    "\n",
    "        # Plot confusion matrices\n",
    "        plot_cm(cm_train, title=f'Confusion Matrix (Train) - {ex.exp_name}',\n",
    "                path=os.path.join(plots_dir, \"confusion_train.png\"), class_names=ex.class_names)\n",
    "        plot_cm(cm_test, title=f'Confusion Matrix (Test) - {ex.exp_name}',\n",
    "                path=os.path.join(plots_dir, \"confusion_test.png\"), class_names=ex.class_names)\n",
    "        plot_cm(cm_train - cm_test, title=f'Confusion Matrix (Train - Test) - {ex.exp_name}',\n",
    "                path=os.path.join(plots_dir, \"confusion_diff.png\"), class_names=ex.class_names)\n",
    "\n",
    "        # Save per-class metrics\n",
    "        save_metrics_csv(metrics_train_per_class, metrics_train_summary, os.path.join(plots_dir, \"metrics_train.csv\"))\n",
    "        save_metrics_csv(metrics_test_per_class, metrics_test_summary, os.path.join(plots_dir, \"metrics_test.csv\"))\n",
    "\n",
    "        # Print summaries\n",
    "        print(f\"\\n--- Summary for {ex.exp_name} ---\")\n",
    "        print(f\"Train accuracy: {acc_train:.4f}, Test accuracy: {acc_test:.4f}, Test ROC AUC: {roc_auc_test:.4f}\")\n",
    "        print(f\"Total training time: {sum(ex.epoch_times):.2f}s, Epoch times: {[round(t,2) for t in ex.epoch_times]}\")\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'exp_name': ex.exp_name,\n",
    "            'train_losses': ex.train_losses,\n",
    "            'epoch_times': ex.epoch_times,\n",
    "            'total_time': sum(ex.epoch_times),\n",
    "            'accuracy_train': acc_train,\n",
    "            'accuracy_test': acc_test,\n",
    "            'report_train': report_train,\n",
    "            'report_test': report_test,\n",
    "            'roc_auc_test': roc_auc_test,\n",
    "            'confusion_train': cm_train,\n",
    "            'confusion_test': cm_test,\n",
    "            'confusion_diff': cm_train - cm_test,\n",
    "            'metrics_test_per_class': metrics_test_per_class,\n",
    "            'metrics_train_per_class': metrics_train_per_class,\n",
    "            'plots_dir': plots_dir\n",
    "        })\n",
    "\n",
    "    # ----------------------------\n",
    "    # High-level comparison summary\n",
    "    # ----------------------------\n",
    "    summary_path = os.path.join(\"plots\", \"comparison_summary.txt\")\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    with open(summary_path, 'w') as f:\n",
    "        f.write(\"Comparison: normalized vs not-normalized\\n\\n\")\n",
    "        for r in results:\n",
    "            f.write(f\"{r['exp_name']} results:\\n\")\n",
    "            f.write(f\"  Train acc: {r['accuracy_train']:.4f}\\n\")\n",
    "            f.write(f\"  Test  acc: {r['accuracy_test']:.4f}\\n\")\n",
    "            f.write(f\"  Total training time: {r['total_time']:.2f}s\\n\\n\")\n",
    "\n",
    "    print(f\"\\nSaved comparison summary to {summary_path}\")\n",
    "    print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
